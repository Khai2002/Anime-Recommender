{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(anime_list): #TODO : Gérer les cas limites \n",
    "    anime_list = anime_list.copy()\n",
    "\n",
    "    ## Dropping columns\n",
    "    columns_to_keep = ['anime_id', 'Name', 'Genres', 'Synopsis', 'Episodes', 'Aired', 'Studios', 'Duration', 'Rating', 'Type', 'Source']\n",
    "    anime_list = anime_list[columns_to_keep]\n",
    "\n",
    "    ## Dealing with Genres : use one-hot encoding \n",
    "    all_genres = set()\n",
    "    for genres in anime_list['Genres']:\n",
    "        all_genres.update(genres.split(', '))\n",
    "    for genre in all_genres:\n",
    "        anime_list[\"Genre \" +genre] = anime_list['Genres'].apply(lambda x: 1 if genre in x.split(', ') else 0)\n",
    "    anime_list.drop(columns=['Genres'], inplace=True)\n",
    "\n",
    "    ## Dealing with Episodes and Duration : calculate total length\n",
    "    anime_list['Episodes'] = pd.to_numeric(anime_list['Episodes'], errors='coerce').fillna(0) #0 if UNKNOWN episodes\n",
    "    hours = anime_list['Duration'].str.extract(r'(\\d+) hr', expand=False).astype(float)\n",
    "    minutes = anime_list['Duration'].str.extract(r'(\\d+) min', expand=False).astype(float)\n",
    "    hours.fillna(0, inplace=True)\n",
    "    minutes.fillna(0, inplace=True)\n",
    "    anime_list['Duration'] = hours * 60 + minutes #0 if UNKNOWN duration\n",
    "    anime_list['Total_Duration'] = anime_list['Duration'] * anime_list['Episodes']\n",
    "\n",
    "    ## Dealing with Aired => get starting date\n",
    "    anime_list['Start_Date'] = pd.to_datetime(anime_list['Aired'].str.split(' to ').str[0], errors='coerce')\n",
    "    anime_list.drop(columns=['Aired'], inplace=True)\n",
    "\n",
    "    ## Dealing with Studios => use one-hot encoding\n",
    "    '''\n",
    "    all_studios = set()\n",
    "    for studio in anime_list['Studios']:\n",
    "        all_studios.update(studio.split(', '))\n",
    "    for studio in all_studios:\n",
    "        anime_list[\"Studio \" + studio] = anime_list['Studios'].apply(lambda x: 1 if studio in x.split(', ') else 0)\n",
    "    anime_list.drop(columns=['Studios'], inplace=True)\n",
    "    '''\n",
    "\n",
    "    ## Dealing with Rating => use one-hot encoding\n",
    "    all_ratings = set()\n",
    "    for rating in anime_list['Rating']:\n",
    "        all_ratings.update(rating.split(', '))\n",
    "    for rating in all_ratings:\n",
    "        anime_list[\"Rating \" + rating] = anime_list['Rating'].apply(lambda x: 1 if rating in x.split(', ') else 0)\n",
    "    anime_list.drop(columns=['Rating'], inplace=True)\n",
    "\n",
    "    ## Dealing with Type => use one-hot encoding\n",
    "    all_types = set()\n",
    "    for type in anime_list['Type']:\n",
    "        all_types.update(type.split(', '))\n",
    "    for type in all_types:\n",
    "        anime_list[\"Type \" + type] = anime_list['Type'].apply(lambda x: 1 if type in x.split(', ') else 0)\n",
    "    anime_list.drop(columns=['Type'], inplace=True)\n",
    "\n",
    "    ## Dealing with Source => use one-hot encoding\n",
    "    all_sources = set()\n",
    "    for source in anime_list['Source']:\n",
    "        all_sources.update(source.split(', '))\n",
    "    for source in all_sources:\n",
    "        anime_list[\"Source \" + source] = anime_list['Source'].apply(lambda x: 1 if source in x.split(', ') else 0)\n",
    "    anime_list.drop(columns=['Source'], inplace=True)\n",
    "\n",
    "    ## Dealing with synopsis\n",
    "    anime_list['Synopsis'] = anime_list['Synopsis'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)).lower())\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    anime_list['Synopsis'] = anime_list['Synopsis'].apply(lambda x  : ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    anime_list['Synopsis'] = anime_list['Synopsis'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
    "    #anime_list['Synopsis'] = anime_list['Synopsis'].apply(lambda x: ' '.join([word for word, pos in pos_tag(word_tokenize(x)) if pos.startswith(('JJ', 'NN', 'VB', 'RB'))])) # add a step to filter names\n",
    "\n",
    "    return anime_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(anime_list):\n",
    "    nbl, nbc = anime_list.shape\n",
    "    print(\"\\nNombre de lignes :\", nbl)\n",
    "    print(\"\\nNombre de colonnes :\", nbc)\n",
    "    print(\"\\nInfos\\n\")\n",
    "    print(anime_list.info())\n",
    "    print(\"\\nDescribe\\n\")\n",
    "    print(anime_list.describe())\n",
    "    print(\"\\nHead\\n\")\n",
    "    print(anime_list.head(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fav_anime_list = [21, 16498, 31964, 38000, 136]\n",
    "fav_anime_list = [21]\n",
    "anime_list = pd.read_parquet('anime/anime.parquet')\n",
    "anime_list = preprocess(anime_list)\n",
    "#show(anime_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_dispersion(df, factor=0.01):\n",
    "    ## Update df, which have values between 0 and 1, to adjust dispersion relatively to 0.5 to a fixed factor, while keeping the values between 0 and 1\n",
    "\n",
    "    # Calculate the current mean absolute deviation from 0.5\n",
    "    current_mad = np.abs(df['similarity'] - 0.5).mean()\n",
    "    \n",
    "    # Scale the values to achieve the desired dispersion relative to 0.5\n",
    "    scaled_values = df['similarity'] + (0.5 - df['similarity']) * (factor / current_mad)\n",
    "    \n",
    "    # Ensure values are between 0 and 1\n",
    "    scaled_values = np.clip(scaled_values, 0, 1)\n",
    "    \n",
    "    df['similarity'] = scaled_values\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_anime(similarities_tab):\n",
    "    sorted_df = similarities_tab.sort_values(by='similarity', ascending=False)\n",
    "    top_anime_ids = sorted_df.head(30)['anime_id'].tolist()\n",
    "    recommended_animes = []\n",
    "    for anime_id in top_anime_ids:\n",
    "        anime_name = anime_list.loc[anime_list['anime_id'] == anime_id, 'Name'].iloc[0]\n",
    "        recommended_animes.append({'anime_id': anime_id, 'Name': anime_name})\n",
    "    return pd.DataFrame(recommended_animes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_anime_global(similarities_tab):\n",
    "    sorted_df = similarities_tab.sort_values(by='total_similarity', ascending=False)\n",
    "    top_anime_ids = sorted_df.head(30)['anime_id'].tolist()\n",
    "    recommended_animes = []\n",
    "    for anime_id in top_anime_ids:\n",
    "        anime_name = anime_list.loc[anime_list['anime_id'] == anime_id, 'Name'].iloc[0]\n",
    "        recommended_animes.append({'anime_id': anime_id, 'Name': anime_name})\n",
    "    return pd.DataFrame(recommended_animes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       anime_id  similarity\n",
      "0             1    0.013469\n",
      "1             5    0.026405\n",
      "2             6    0.027187\n",
      "3             7    0.005047\n",
      "4             8    0.031917\n",
      "...         ...         ...\n",
      "24897     55731    0.000000\n",
      "24898     55732    0.000000\n",
      "24899     55733    0.000000\n",
      "24900     55734    0.000000\n",
      "24901     55735    0.000000\n",
      "\n",
      "[24902 rows x 2 columns]\n",
      "       anime_id  similarity\n",
      "0             1    0.023371\n",
      "1             5    0.036043\n",
      "2             6    0.036809\n",
      "3             7    0.015120\n",
      "4             8    0.041444\n",
      "...         ...         ...\n",
      "24897     55731    0.010176\n",
      "24898     55732    0.010176\n",
      "24899     55733    0.010176\n",
      "24900     55734    0.010176\n",
      "24901     55735    0.010176\n",
      "\n",
      "[24902 rows x 2 columns]\n",
      "    anime_id                                               Name\n",
      "0      12859                                  One Piece Film: Z\n",
      "1      36215  One Piece: Episode of East Blue - Luffy to 4-n...\n",
      "2      38234                       One Piece Movie 14: Stampede\n",
      "3       5252                      One Piece: Romance Dawn Story\n",
      "4       8740             One Piece Film: Strong World Episode 0\n",
      "5       1237  One Piece: Oounabara ni Hirake! Dekkai Dekkai ...\n",
      "6      19505                                       Kaizoku Ouji\n",
      "7       1638                                Peter Pan no Bouken\n",
      "8       4155                       One Piece Film: Strong World\n",
      "9        464  One Piece Movie 06: Omatsuri Danshaku to Himit...\n",
      "10     50385                           One Piece Characters Log\n",
      "11       459                                 One Piece Movie 01\n",
      "12     50410                                One Piece Film: Red\n",
      "13      1238              One Piece: Mamore! Saigo no Dai Butai\n",
      "14     14817              Mouretsu Pirates: Abyss of Hyperspace\n",
      "15     51163  One Piece: Mugiwara no Ichimi kara no Kansen Y...\n",
      "16     18315                   Nareuneun Dwaeji - Haejeok Mateo\n",
      "17     33165                                    Mashou no Nie 3\n",
      "18     31289  One Piece: Episode of Sabo - 3 Kyoudai no Kizu...\n",
      "19      2451                                        Space Cobra\n",
      "20     50696               One Piece: Barto no Himitsu no Heya!\n",
      "21       462             One Piece Movie 04: Dead End no Bouken\n",
      "22      2699                    Uchuu Kaizoku Mito no Daibouken\n",
      "23     25161  One Piece 3D2Y: Ace no shi wo Koete! Luffy Nak...\n",
      "24       465   One Piece Movie 07: Karakuri-jou no Mecha Kyohei\n",
      "25      2618                                         Takarajima\n",
      "26     38419  Tokyo One Piece Tower: Tongari Shima no Dai Hihou\n",
      "27     33338                           One Piece: Heart of Gold\n",
      "28      9999                       One Piece 3D: Mugiwara Chase\n",
      "29     13169                                               Buta\n"
     ]
    }
   ],
   "source": [
    "### Synopsis\n",
    "\n",
    "\n",
    "def extract_keywords(anime_ids, anime_list):\n",
    "    # récupérer tous les synopsis des animes favoris\n",
    "    fav_anime_synopsis = anime_list.loc[anime_list['anime_id'].isin(anime_ids), 'Synopsis'].tolist()\n",
    "    # concaténer l'ensemble de ces synopsis\n",
    "    fav_anime_synopsis = ' '.join(fav_anime_synopsis)\n",
    "    # récupérer les mots clés\n",
    "    fav_anime_keywords = fav_anime_synopsis.split()\n",
    "    fav_anime_keywords = [word.translate(str.maketrans('', '', string.punctuation)).lower() for word in fav_anime_keywords]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    fav_anime_keywords = [word for word in fav_anime_keywords if word not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    fav_anime_keywords = [lemmatizer.lemmatize(word) for word in fav_anime_keywords]\n",
    "    return ' '.join(fav_anime_keywords)\n",
    "\n",
    "\n",
    "def recommendation_synopsis_based(fav_anime_list, anime_list):\n",
    "    # Extraction de mots-clés des synopsis des animes favoris\n",
    "    fav_anime_keywords = extract_keywords(fav_anime_list, anime_list)\n",
    "\n",
    "    anime_ids = anime_list.loc[~anime_list['anime_id'].isin(fav_anime_list), 'anime_id'].values\n",
    "\n",
    "    # Calcul de la similarité cosinus entre les mots-clés générés des animes favoris et les synopsis de tous les autres animes\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix_other_anime = tfidf_vectorizer.fit_transform(anime_list.loc[~anime_list['anime_id'].isin(fav_anime_list), 'Synopsis'])\n",
    "    tfidf_matrix_fav_anime = tfidf_vectorizer.transform([fav_anime_keywords]) \n",
    "    cosine_similarities = cosine_similarity(tfidf_matrix_other_anime, tfidf_matrix_fav_anime)\n",
    "\n",
    "    return pd.DataFrame({'anime_id': anime_ids, 'similarity': cosine_similarities.flatten()})\n",
    "\n",
    "\n",
    "synopsis_cosine_similarities_tab = recommendation_synopsis_based(fav_anime_list, anime_list)\n",
    "print(synopsis_cosine_similarities_tab)\n",
    "\n",
    "synopsis_cosine_similarities_tab = adjust_dispersion(synopsis_cosine_similarities_tab)\n",
    "\n",
    "print(synopsis_cosine_similarities_tab)\n",
    "recommended_animes = recommend_anime(synopsis_cosine_similarities_tab)\n",
    "print(recommended_animes[['anime_id', 'Name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       anime_id  similarity\n",
      "0             1    0.337689\n",
      "1             5    0.337689\n",
      "2             6    0.662311\n",
      "3             7    0.337689\n",
      "4             8    0.662311\n",
      "...         ...         ...\n",
      "24897     55731    0.337689\n",
      "24898     55732    0.986932\n",
      "24899     55733    0.986932\n",
      "24900     55734    0.013068\n",
      "24901     55735    0.013068\n",
      "\n",
      "[24902 rows x 2 columns]\n",
      "    anime_id                                               Name\n",
      "0      27825                         Long Zhi Gu: Poxiao Qibing\n",
      "1      38198          Nanatsu no Taizai: Eiyuu-tachi wa Hashagu\n",
      "2      31821                    Arslan Senki (TV): Fuujin Ranbu\n",
      "3      19951          Hunter x Hunter Movie 2: The Last Mission\n",
      "4      51162  One Piece: Otoshidama Special - Tokubetsu Hou ...\n",
      "5      40734                             Yao Shen Ji 4th Season\n",
      "6      52368                                      AOTU Shijie 4\n",
      "7       6633               Queen's Blade: Gyokuza wo Tsugu Mono\n",
      "8      37254         Last Period: Owarinaki Rasen no Monogatari\n",
      "9      43523                  Tsuki ga Michibiku Isekai Douchuu\n",
      "10     37262                            Ta ga Tame no Alchemist\n",
      "11     36345                                      AOTU Shijie 2\n",
      "12      9521                                   Tie Shan Gongzhu\n",
      "13      2249                                          Amon Saga\n",
      "14     38297                                  Maou-sama, Retry!\n",
      "15     52357  Dungeon ni Deai wo Motomeru no wa Machigatteir...\n",
      "16     31838                                         Ze Tian Ji\n",
      "17     52347  Shangri-La Frontier: Kusoge Hunter, Kamige ni ...\n",
      "18     40783                     Shachou, Battle no Jikan desu!\n",
      "19       709                              Mujin Wakusei Survive\n",
      "20     31859                           Hai to Gensou no Grimgar\n",
      "21     38268              Hangyakusei Million Arthur 2nd Season\n",
      "22      4437                Naruto: Shippuuden Movie 2 - Kizuna\n",
      "23     20159                                Pokemon: The Origin\n",
      "24      1331                                        Dragon Pink\n",
      "25     38234                       One Piece Movie 14: Stampede\n",
      "26     38220                              Ze Tian Ji 4th Season\n",
      "27     41667                                           Monkateu\n",
      "28     51145     Pokemon Legends Arceus: Yuki Hodo Kishi Futaai\n",
      "29     37232  Merc Storia: Mukiryoku no Shounen to Bin no Na...\n"
     ]
    }
   ],
   "source": [
    "### Genre\n",
    "##Limit case : check that every anime in fav_anime_list has not Genre_UNKNOWN, if not delete this anime from the list to build fav_genres_prop\n",
    "\n",
    "def recommendation_genre_based(fav_anime_list, anime_list):\n",
    "    anime_ids = anime_list.loc[~anime_list['anime_id'].isin(fav_anime_list), 'anime_id'].values\n",
    "\n",
    "    if not fav_anime_list:\n",
    "        return pd.DataFrame({'anime_id': anime_ids, 'similarity': 0})\n",
    "    \n",
    "    similarities = []\n",
    "\n",
    "    fav_genres = anime_list.loc[anime_list['anime_id'].isin(fav_anime_list), anime_list.filter(regex='^Genre').columns].sum()\n",
    "    fav_genres_prop = fav_genres / fav_genres.sum()\n",
    "\n",
    "    other_anime_genres = anime_list.loc[~anime_list['anime_id'].isin(fav_anime_list), anime_list.filter(regex='^Genre').columns]\n",
    "    for _, row in other_anime_genres.iterrows():\n",
    "        genre_similarity = sum(row[genre] * fav_genres_prop[genre] for genre in fav_genres_prop.index)\n",
    "        similarities.append(genre_similarity)\n",
    "       \n",
    "    return pd.DataFrame({'anime_id': anime_ids, 'similarity': similarities})\n",
    "\n",
    "fav_anime_list = [anime_id for anime_id in fav_anime_list if anime_list.loc[anime_list['anime_id'] == anime_id, 'Genre UNKNOWN'].values[0] == 0]\n",
    "\n",
    "genre_cosine_similarities_tab = recommendation_genre_based(fav_anime_list, anime_list)\n",
    "genre_cosine_similarities_tab = adjust_dispersion(genre_cosine_similarities_tab)\n",
    "\n",
    "print(genre_cosine_similarities_tab)\n",
    "\n",
    "recommended_animes = recommend_anime(genre_cosine_similarities_tab)\n",
    "print(recommended_animes[['anime_id', 'Name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating G - All Ages                      0.0\n",
      "Rating PG - Children                     0.0\n",
      "Rating PG-13 - Teens 13 or older         1.0\n",
      "Rating R - 17+ (violence & profanity)    0.0\n",
      "Rating R+ - Mild Nudity                  0.0\n",
      "Rating Rx - Hentai                       0.0\n",
      "Rating UNKNOWN                           0.0\n",
      "dtype: float64\n",
      "       anime_id  similarity\n",
      "0             1        0.01\n",
      "1             5        0.01\n",
      "2             6        0.99\n",
      "3             7        0.99\n",
      "4             8        0.01\n",
      "...         ...         ...\n",
      "24897     55731        0.99\n",
      "24898     55732        0.99\n",
      "24899     55733        0.99\n",
      "24900     55734        0.99\n",
      "24901     55735        0.99\n",
      "\n",
      "[24902 rows x 2 columns]\n",
      "    anime_id                                               Name\n",
      "0      55735                                     Shijuuku Nichi\n",
      "1      19053                           Kaitou Jigoma Ongaku-hen\n",
      "2      47375                                Mei Shaonu Da Picha\n",
      "3      18967          Zukkoke Sannin-gumi: Zukkoke Jikuu Bouken\n",
      "4      18989            Koukaku Kidoutai Arise: Another Mission\n",
      "5      19021  Takanashi Rikka Kai: Chuunibyou demo Koi ga Sh...\n",
      "6      19023                                    Wake Up, Girls!\n",
      "7      19029                             Yuyushiki: Nyanyashiki\n",
      "8      47366                                   Ju Shu 5 Sui Hua\n",
      "9      47351                                           Kaibutsu\n",
      "10     18897                                            Nisekoi\n",
      "11     19109            Fate/kaleid liner Prisma☆Illya Specials\n",
      "12     19111          Love Live! School Idol Project 2nd Season\n",
      "13     19115                                  Giovanni no Shima\n",
      "14     19117                         Toaru Hikuushi e no Koiuta\n",
      "15     47347                                  Kuang Wan Zhan Ji\n",
      "16     19123  One Piece: Episode of Merry - Mou Hitori no Na...\n",
      "17     19133                                      Turning Girls\n",
      "18     18919                                The Midnight★Animal\n",
      "19     18893                  Aoki Hagane no Arpeggio: Ars Nova\n",
      "20     19177  Chiisana Love Letter: Mariko to Nemunoki no Ko...\n",
      "21     18781  Puchimas!: Petit iDOLM@STER - Takatsuki Gold D...\n",
      "22     18743          Money Wars: Nerawareta Waterfront Keikaku\n",
      "23     18745   Chihayafuru 2: Waga Miyo ni Furu Nagame Shima ni\n",
      "24     47405                                      Wanmei Shijie\n",
      "25     18753  Yahari Ore no Seishun Love Comedy wa Machigatt...\n",
      "26     47398  Chuukou Ikkan!! Kimetsu Gakuen Monogatari: Val...\n",
      "27     47394                       Wangzhe? Bie Nao! 2nd Season\n",
      "28     47393                           Wangzhe? Bie Nao! Fanwai\n",
      "29     18795                             Dagram vs. Round-Facer\n"
     ]
    }
   ],
   "source": [
    "### Rating\n",
    "##Limit case : check that every anime in fav_anime_list has not Rating UNKNOWN, if not delete this anime from the list to build fav_ratings_prop\n",
    "\n",
    "def recommendation_rating_based(fav_anime_list, anime_list):\n",
    "    anime_ids = anime_list.loc[~anime_list['anime_id'].isin(fav_anime_list), 'anime_id'].values\n",
    "\n",
    "    if not fav_anime_list:\n",
    "        return pd.DataFrame({'anime_id': anime_ids, 'similarity': 0})\n",
    "    \n",
    "    similarities = []\n",
    "\n",
    "    fav_ratings = anime_list.loc[anime_list['anime_id'].isin(fav_anime_list), anime_list.filter(regex='^Rating').columns].sum()\n",
    "    fav_ratings_prop = fav_ratings / fav_ratings.sum()\n",
    "\n",
    "    print(fav_ratings_prop)\n",
    "\n",
    "    other_anime_ratings = anime_list.loc[~anime_list['anime_id'].isin(fav_anime_list), anime_list.filter(regex='^Rating').columns]\n",
    "    for _, row in other_anime_ratings.iterrows():\n",
    "        rating_similarity = sum(row[rate] * fav_ratings_prop[rate] for rate in fav_ratings_prop.index)\n",
    "        similarities.append(rating_similarity)\n",
    "       \n",
    "    return pd.DataFrame({'anime_id': anime_ids, 'similarity': similarities})\n",
    "\n",
    "fav_anime_list = [anime_id for anime_id in fav_anime_list if anime_list.loc[anime_list['anime_id'] == anime_id, 'Rating UNKNOWN'].values[0] == 0]\n",
    "\n",
    "rating_cosine_similarities_tab = recommendation_rating_based(fav_anime_list, anime_list)\n",
    "rating_cosine_similarities_tab = adjust_dispersion(rating_cosine_similarities_tab)\n",
    "\n",
    "print(rating_cosine_similarities_tab)\n",
    "\n",
    "recommended_animes = recommend_anime(rating_cosine_similarities_tab)\n",
    "print(recommended_animes[['anime_id', 'Name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21]\n",
      "       anime_id  similarity\n",
      "0             1        0.99\n",
      "1             5        0.01\n",
      "2             6        0.99\n",
      "3             7        0.99\n",
      "4             8        0.99\n",
      "...         ...         ...\n",
      "24897     55731        0.01\n",
      "24898     55732        0.01\n",
      "24899     55733        0.01\n",
      "24900     55734        0.01\n",
      "24901     55735        0.01\n",
      "\n",
      "[24902 rows x 2 columns]\n",
      "    anime_id                                               Name\n",
      "0          1                                       Cowboy Bebop\n",
      "1      46599                                  Xiaohu Da Guanjia\n",
      "2      46575                    Kuaile Baobei: Cheng Chang Riji\n",
      "3      46574                        Kuaile Baobei: Huanle Jiaqi\n",
      "4      46573                     Kuaile Baobei: Duocai Shenghuo\n",
      "5      19221  Ore no Nounai Sentakushi ga, Gakuen Love Comed...\n",
      "6      46572                       Kuaile Baobei: Xingqu Mofang\n",
      "7      46571                       Kuaile Baobei: Huoli Jiating\n",
      "8      46570                       Kuaile Baobei: Bai Bian Zimu\n",
      "9      46569                                         Jigokuraku\n",
      "10     46567                 Senlin Hao Huoban: Kuaile Shenghuo\n",
      "11     46566                                    Haixing Xiongdi\n",
      "12     46565                                  Bu Erduo De Gushi\n",
      "13     19257                                         Megane-bu!\n",
      "14     46564          Tunshu Zhen Kuaile Shenghuo: Yanyu Leyuan\n",
      "15     46563                     Tunshu Zhi Shi Wan Ge Weisheme\n",
      "16     46562                 Tunshu Xiao Zhen: Le You Da Shijie\n",
      "17     46561      Tunshu Zhen Huwai Anquan Ji Zijiu Zi Hu Xilie\n",
      "18     46560               Tunshu Jiating Xiaoyuan Anquan Xilie\n",
      "19     46576                Kuaile Baobei: Duo Mi Chengzhang Ji\n",
      "20     46577                   Qi Qu Gong Fang: Jianzhi Baodian\n",
      "21     19207  Maji de Otaku na English! Ribbon-chan: Eigo de...\n",
      "22     46591              Tian Tian Quan Baobei: Feixing Leyuan\n",
      "23     19121                                Doctor Chichibuyama\n",
      "24     46597                        Feichang Xiaozi Ma Ming Jia\n",
      "25     46595                             Fu Le Xunbao Lixian Ji\n",
      "26     46594            Tian Tian Quan Baobei: Saiche Xiao Zhen\n",
      "27     46592              Tian Tian Quan Baobei: Mifeng Huayuan\n",
      "28     19151                                    Walkure Romanze\n",
      "29     19157                                       Youkai Watch\n"
     ]
    }
   ],
   "source": [
    "### Type \n",
    "##Limit case : check that every anime in fav_anime_list has not \"Type UNKNOWN\", if not delete this anime from the list to build fav_types_prop\n",
    "\n",
    "def recommendation_type_based(fav_anime_list, anime_list):\n",
    "    anime_ids = anime_list.loc[~anime_list['anime_id'].isin(fav_anime_list), 'anime_id'].values\n",
    "\n",
    "    if not fav_anime_list:\n",
    "        return pd.DataFrame({'anime_id': anime_ids, 'similarity': 0})\n",
    "    \n",
    "    similarities = []\n",
    "\n",
    "    fav_types = anime_list.loc[anime_list['anime_id'].isin(fav_anime_list), anime_list.filter(regex='^Type').columns].sum()\n",
    "    fav_types_prop = fav_types / fav_types.sum()\n",
    "\n",
    "    other_anime_types = anime_list.loc[~anime_list['anime_id'].isin(fav_anime_list), anime_list.filter(regex='^Type').columns]\n",
    "    for _, row in other_anime_types.iterrows():\n",
    "        type_similarity = sum(row[type] * fav_types_prop[type] for type in fav_types_prop.index)\n",
    "        similarities.append(type_similarity)\n",
    "       \n",
    "    return pd.DataFrame({'anime_id': anime_ids, 'similarity': similarities})\n",
    "\n",
    "fav_anime_list = [anime_id for anime_id in fav_anime_list if anime_list.loc[anime_list['anime_id'] == anime_id, 'Type UNKNOWN'].values[0] == 0]\n",
    "\n",
    "print(fav_anime_list)\n",
    "\n",
    "type_cosine_similarities_tab = recommendation_type_based(fav_anime_list, anime_list)\n",
    "type_cosine_similarities_tab = adjust_dispersion(type_cosine_similarities_tab)\n",
    "\n",
    "print(type_cosine_similarities_tab)\n",
    "\n",
    "recommended_animes = recommend_anime(type_cosine_similarities_tab)\n",
    "print(recommended_animes[['anime_id', 'Name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21]\n",
      "       anime_id  similarity\n",
      "0             1        0.01\n",
      "1             5        0.01\n",
      "2             6        0.99\n",
      "3             7        0.01\n",
      "4             8        0.99\n",
      "...         ...         ...\n",
      "24897     55731        0.01\n",
      "24898     55732        0.01\n",
      "24899     55733        0.01\n",
      "24900     55734        0.01\n",
      "24901     55735        0.01\n",
      "\n",
      "[24902 rows x 2 columns]\n",
      "    anime_id                                               Name\n",
      "0      14227                             Tonari no Kaibutsu-kun\n",
      "1      40801  Aisei Tenshi Love Mary: Akusei Jutai - The Ani...\n",
      "2      33069  Dimension W: Short Track/Robot wa Sentou no Yu...\n",
      "3      33071                    Bungou Stray Dogs: Hitori Ayumu\n",
      "4      50695                                           MF Ghost\n",
      "5      50696               One Piece: Barto no Himitsu no Heya!\n",
      "6       6203                                      Sasameki Koto\n",
      "7      33074                          Lupin III (2015) Specials\n",
      "8       6198  Detective Conan OVA 08: High School Girl Detec...\n",
      "9      33077                    Terajima-chou Kidan: Ginnagashi\n",
      "10      6194                              Stretta The Animation\n",
      "11      6187                               Nodame Cantabile OVA\n",
      "12      6184                            Makaryuudo Demon Hunter\n",
      "13     50710                              Urusei Yatsura (2022)\n",
      "14      6171        Saint Seiya: The Lost Canvas - Meiou Shinwa\n",
      "15      6164                                           Aoi Hana\n",
      "16      6163                                 Kuroshitsuji Recap\n",
      "17      6153                                  Saint Seiya Recap\n",
      "18     33095  Shouwa Genroku Rakugo Shinjuu: Sukeroku Futata...\n",
      "19     40776                        Haikyuu!! To the Top Part 2\n",
      "20      6149                           Chibi Maruko-chan (1995)\n",
      "21      6213                            Toaru Kagaku no Railgun\n",
      "22      6217      Crayon Shin-chan Movie 03: Unkokusai no Yabou\n",
      "23     50608                  Tokyo Revengers: Seiya Kessen-hen\n",
      "24     40806                    Huyao Xiao Hongniang: Wei Sheng\n",
      "25      6324                                     Omamori Himari\n",
      "26     50612                                 Dr. Stone: Ryuusui\n",
      "27      6312  Taiho Shichau zo: Full Throttle - Watashitachi...\n",
      "28     50613     Rurouni Kenshin: Meiji Kenkaku Romantan (2023)\n",
      "29     50621                     Oni no Hanayome wa Taberaretai\n"
     ]
    }
   ],
   "source": [
    "### Source \n",
    "##Limit case : check that every anime in fav_anime_list has not \"Source Unknown\", if not delete this anime from the list to build fav_sources_prop\n",
    "\n",
    "def recommendation_source_based(fav_anime_list, anime_list):\n",
    "    anime_ids = anime_list.loc[~anime_list['anime_id'].isin(fav_anime_list), 'anime_id'].values\n",
    "\n",
    "    if not fav_anime_list:\n",
    "        return pd.DataFrame({'anime_id': anime_ids, 'similarity': 0})\n",
    "    \n",
    "    similarities = []\n",
    "\n",
    "    fav_sources = anime_list.loc[anime_list['anime_id'].isin(fav_anime_list), anime_list.filter(regex='^Source').columns].sum()\n",
    "    fav_sources_prop = fav_sources / fav_sources.sum()\n",
    "\n",
    "    other_anime_sources = anime_list.loc[~anime_list['anime_id'].isin(fav_anime_list), anime_list.filter(regex='^Source').columns]\n",
    "    for _, row in other_anime_sources.iterrows():\n",
    "        source_similarity = sum(row[source] * fav_sources_prop[source] for source in fav_sources_prop.index)\n",
    "        similarities.append(source_similarity)\n",
    "       \n",
    "    return pd.DataFrame({'anime_id': anime_ids, 'similarity': similarities})\n",
    "\n",
    "fav_anime_list = [anime_id for anime_id in fav_anime_list if anime_list.loc[anime_list['anime_id'] == anime_id, 'Source Unknown'].values[0] == 0]\n",
    "print(fav_anime_list)\n",
    "\n",
    "source_cosine_similarities_tab = recommendation_source_based(fav_anime_list, anime_list)\n",
    "source_cosine_similarities_tab = adjust_dispersion(source_cosine_similarities_tab)\n",
    "\n",
    "print(source_cosine_similarities_tab)\n",
    "\n",
    "recommended_animes = recommend_anime(source_cosine_similarities_tab)\n",
    "print(recommended_animes[['anime_id', 'Name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       anime_id  similarity\n",
      "0             1    0.839975\n",
      "1             5    0.166639\n",
      "2             6    0.839975\n",
      "3             7    0.874369\n",
      "4             8    0.610412\n",
      "...         ...         ...\n",
      "24894     55731    0.500000\n",
      "24895     55732    0.500000\n",
      "24896     55733    0.500000\n",
      "24897     55734    0.018479\n",
      "24898     55735    0.018479\n",
      "\n",
      "[24899 rows x 2 columns]\n",
      "    anime_id                                               Name\n",
      "0      48904                                 Digital Tokoro-san\n",
      "1      46521                                     Mimi Zhao Mama\n",
      "2       1137                                          Mushrambo\n",
      "3      14333                                     Tanken Driland\n",
      "4      45741                          Dou Dou Hu Shuxue Wangguo\n",
      "5      46156                                  Tian Jiang Xiaozi\n",
      "6      45738                                         Dou Dou Hu\n",
      "7      45740                        Dou Dou Hu Hanzi Daxue Tang\n",
      "8      45746                       Dou Dou Hu Zheng Shi Tianxia\n",
      "9      47443              Wulongyuan: Huobao Chuanqi 2nd Season\n",
      "10     47442                         Wulongyuan: Huobao Chuanqi\n",
      "11     46216  Shengxiao Chuanqi: Shi Er Shengxiao Chuangjianghu\n",
      "12     45721                                    Bodhi Yu Haoyou\n",
      "13     46345                                     Jingji Xueyuan\n",
      "14     47215                                   Feitian Shaonian\n",
      "15     11177                                Cross Fight B-Daman\n",
      "16     46704                              Lanting Xiao Jingling\n",
      "17     47112                                       Xia Xiao Dou\n",
      "18     45735                       Dou Dou Hu Huihua Xiaotiandi\n",
      "19     45662                                        Rubi Yoyo 3\n",
      "20     45097                             Wo de Pengyou Zhu Dike\n",
      "21     46907                                  Dongnan Te Weidui\n",
      "22     35542                                   Turning Mecard W\n",
      "23     35543                          Turning Mecard W Season 2\n",
      "24      3665                 Ginga Eiyuu Densetsu Gaiden (1999)\n",
      "25     39282                               Beyblade Burst Gachi\n",
      "26     40091                           Xiao Hua Xian 2nd Season\n",
      "27     21019                                           Noonbory\n",
      "28     44958                                     Shuiguo Baobei\n",
      "29     47079                             Mengxiang Zongdongyuan\n"
     ]
    }
   ],
   "source": [
    "### Duration\n",
    "## Limit case : check that every anime in fav_anime_list has not UNKNOWN for episodes or duration, if not delete this anime from the list to build avg_fav_duration\n",
    "\n",
    "def recommendation_duration_based(fav_anime_list, anime_list):\n",
    "\n",
    "    anime_ids = anime_list.loc[~anime_list['anime_id'].isin(fav_anime_list), 'anime_id'].values\n",
    "\n",
    "    if not fav_anime_list:\n",
    "        return pd.DataFrame({'anime_id': anime_ids, 'similarity': 0})\n",
    "    \n",
    "    \n",
    "    similarities = []\n",
    "\n",
    "    avg_fav_duration = anime_list.loc[anime_list['anime_id'].isin(fav_anime_list), 'Total_Duration'].mean()\n",
    "\n",
    "    other_anime_durations = anime_list.loc[~anime_list['anime_id'].isin(fav_anime_list), 'Total_Duration']\n",
    "\n",
    "    for duration in other_anime_durations:\n",
    "        if duration != 0:\n",
    "            relative_difference = abs(duration - avg_fav_duration) / max(duration, avg_fav_duration)\n",
    "            duration_similarity = 1 - relative_difference\n",
    "        else:\n",
    "            duration_similarity = 0.5 #similarity equals 0.5 if duration equals 0 (meaning UNKNOW number of episodes or UNKNOW duration)\n",
    "        similarities.append(duration_similarity)\n",
    "\n",
    "    return pd.DataFrame({'anime_id': anime_ids, 'similarity': similarities})\n",
    "\n",
    "#Filtering anime with missing information\n",
    "fav_anime_list = [anime_id for anime_id in fav_anime_list if anime_list.loc[anime_list['anime_id'] == anime_id, 'Episodes'].values[0] != 0]\n",
    "fav_anime_list = [anime_id for anime_id in fav_anime_list if anime_list.loc[anime_list['anime_id'] == anime_id, 'Duration'].values[0] != 0]\n",
    "\n",
    "duration_cosine_similarities_tab = recommendation_duration_based(fav_anime_list, anime_list)\n",
    "duration_cosine_similarities_tab = adjust_dispersion(duration_cosine_similarities_tab)\n",
    "print(duration_cosine_similarities_tab)\n",
    "\n",
    "recommended_animes = recommend_anime(duration_cosine_similarities_tab)\n",
    "print(recommended_animes[['anime_id', 'Name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_fav_anime_list(fav_anime_list, anime_list, feature):\n",
    "    if feature == 'genre':\n",
    "        filtered_fav_anime_list = [anime_id for anime_id in fav_anime_list if anime_list.loc[anime_list['anime_id'] == anime_id, 'Genre UNKNOWN'].values[0] == 0]\n",
    "    elif feature == 'duration':\n",
    "        filtered_fav_anime_list = [anime_id for anime_id in fav_anime_list if anime_list.loc[anime_list['anime_id'] == anime_id, 'Episodes'].values[0] != 0 and anime_list.loc[anime_list['anime_id'] == anime_id, 'Duration'].values[0] != 0]\n",
    "    elif feature == 'type':\n",
    "        filtered_fav_anime_list = [anime_id for anime_id in fav_anime_list if anime_list.loc[anime_list['anime_id'] == anime_id, 'Type UNKNOWN'].values[0] == 0]\n",
    "    elif feature == 'source':\n",
    "        filtered_fav_anime_list = [anime_id for anime_id in fav_anime_list if anime_list.loc[anime_list['anime_id'] == anime_id, 'Source Unknown'].values[0] == 0]\n",
    "    elif feature == 'rating':\n",
    "        filtered_fav_anime_list = [anime_id for anime_id in fav_anime_list if anime_list.loc[anime_list['anime_id'] == anime_id, 'Rating UNKNOWN'].values[0] == 0]\n",
    "    else:\n",
    "        filtered_fav_anime_list = fav_anime_list\n",
    "    return filtered_fav_anime_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    anime_id                                               Name\n",
      "0      25777                        Shingeki no Kyojin Season 2\n",
      "1      51019           Kimetsu no Yaiba: Katanakaji no Sato-hen\n",
      "2      11061                             Hunter x Hunter (2011)\n",
      "3      36215  One Piece: Episode of East Blue - Luffy to 4-n...\n",
      "4      36456                   Boku no Hero Academia 3rd Season\n",
      "5      35760                        Shingeki no Kyojin Season 3\n",
      "6      12859                                  One Piece Film: Z\n",
      "7      38524                 Shingeki no Kyojin Season 3 Part 2\n",
      "8      36702  Shingeki no Kyojin Season 2 Movie: Kakusei no ...\n",
      "9      33486                   Boku no Hero Academia 2nd Season\n",
      "10     38234                       One Piece Movie 14: Stampede\n",
      "11      1237  One Piece: Oounabara ni Hirake! Dekkai Dekkai ...\n",
      "12     40028               Shingeki no Kyojin: The Final Season\n",
      "13     31374                        Shingeki! Kyojin Chuugakkou\n",
      "14     40906              Dragon Quest: Dai no Daibouken (2020)\n",
      "15     50410                                One Piece Film: Red\n",
      "16     51020                                              Helck\n",
      "17     48583        Shingeki no Kyojin: The Final Season Part 2\n",
      "18       464  One Piece Movie 06: Omatsuri Danshaku to Himit...\n",
      "19     19505                                       Kaizoku Ouji\n",
      "20     14833                                 Maoyuu Maou Yuusha\n",
      "21      4155                       One Piece Film: Strong World\n",
      "22     49926                 Kimetsu no Yaiba: Mugen Ressha-hen\n",
      "23     41834               King's Raid: Ishi wo Tsugumono-tachi\n",
      "24     47778                      Kimetsu no Yaiba: Yuukaku-hen\n",
      "25      5252                      One Piece: Romance Dawn Story\n",
      "26     18397                             Shingeki no Kyojin OVA\n",
      "27     34745                           Mahoujin Guruguru (2017)\n",
      "28     42625                        Heion Sedai no Idaten-tachi\n",
      "29     13271             Hunter x Hunter Movie 1: Phantom Rouge\n"
     ]
    }
   ],
   "source": [
    "## Final combination\n",
    "\n",
    "fav_anime_list = [21, 16498, 31964, 38000, 136]\n",
    "#fav_anime_list = [21]\n",
    "\n",
    "anime_list = pd.read_parquet('anime/anime.parquet')\n",
    "anime_list = preprocess(anime_list)\n",
    "\n",
    "genre_cosine_similarities_tab = recommendation_genre_based(preprocess_fav_anime_list(fav_anime_list, anime_list, 'genre'), anime_list)\n",
    "genre_cosine_similarities_tab = adjust_dispersion(genre_cosine_similarities_tab)\n",
    "\n",
    "duration_cosine_similarities_tab = recommendation_duration_based(preprocess_fav_anime_list(fav_anime_list, anime_list, 'duration'), anime_list)\n",
    "duration_cosine_similarities_tab = adjust_dispersion(duration_cosine_similarities_tab)\n",
    "\n",
    "synopsis_cosine_similarities_tab = recommendation_synopsis_based(preprocess_fav_anime_list(fav_anime_list, anime_list, 'synopsis'), anime_list)\n",
    "synopsis_cosine_similarities_tab = adjust_dispersion(synopsis_cosine_similarities_tab)\n",
    "\n",
    "rating_cosine_similarities_tab = recommendation_source_based(preprocess_fav_anime_list(fav_anime_list, anime_list, 'rating'), anime_list)\n",
    "rating_cosine_similarities_tab = adjust_dispersion(rating_cosine_similarities_tab)\n",
    "\n",
    "type_cosine_similarities_tab = recommendation_type_based(preprocess_fav_anime_list(fav_anime_list, anime_list, 'type'), anime_list)\n",
    "type_cosine_similarities_tab = adjust_dispersion(type_cosine_similarities_tab)\n",
    "\n",
    "source_cosine_similarities_tab = recommendation_source_based(preprocess_fav_anime_list(fav_anime_list, anime_list, 'source'), anime_list)\n",
    "source_cosine_similarities_tab = adjust_dispersion(source_cosine_similarities_tab)\n",
    "\n",
    "'''\n",
    "print(genre_cosine_similarities_tab)\n",
    "print(duration_cosine_similarities_tab)\n",
    "print(synopsis_cosine_similarities_tab)\n",
    "print(type_cosine_similarities_tab)\n",
    "print(source_cosine_similarities_tab)\n",
    "print(rating_cosine_similarities_tab)\n",
    "'''\n",
    "\n",
    "\n",
    "combined_tab = pd.merge(genre_cosine_similarities_tab, duration_cosine_similarities_tab, on='anime_id', suffixes=('_genre', '_duration'))\n",
    "combined_tab = pd.merge(combined_tab, synopsis_cosine_similarities_tab, on='anime_id', suffixes=('_', '_synopsis'))\n",
    "combined_tab = pd.merge(combined_tab, type_cosine_similarities_tab, on='anime_id', suffixes=('', '_type'))\n",
    "combined_tab = pd.merge(combined_tab, source_cosine_similarities_tab, on='anime_id', suffixes=('', '_source'))\n",
    "combined_tab = pd.merge(combined_tab, rating_cosine_similarities_tab, on='anime_id', suffixes=('', '_rating'))\n",
    "\n",
    "#print(combined_tab)\n",
    "\n",
    "\n",
    "# Calculate total similarity\n",
    "combined_tab['total_similarity'] = (\n",
    "    0.05 * combined_tab['similarity_genre'] +\n",
    "    0.01 * combined_tab['similarity_duration'] +\n",
    "    0.90 * combined_tab['similarity'] + #synopsis\n",
    "    0.02 * combined_tab['similarity_type'] +\n",
    "    0.01 * combined_tab['similarity_source'] + \n",
    "    0.01 * combined_tab['similarity_rating']\n",
    ")\n",
    "\n",
    "recommended_animes = recommend_anime_global(combined_tab)\n",
    "print(recommended_animes[['anime_id', 'Name']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
