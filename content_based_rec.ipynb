{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(anime_list): #TODO : Gérer les cas limites \n",
    "    anime_list = anime_list.copy()\n",
    "\n",
    "    ## Dropping columns\n",
    "    columns_to_keep = ['anime_id', 'Name', 'Genres', 'Synopsis', 'Episodes', 'Aired', 'Studios', 'Duration', 'Rating', 'Type', 'Source']\n",
    "    anime_list = anime_list[columns_to_keep]\n",
    "\n",
    "    ## Dealing with Genres : use one-hot encoding \n",
    "    all_genres = set()\n",
    "    for genres in anime_list['Genres']:\n",
    "        all_genres.update(genres.split(', '))\n",
    "    for genre in all_genres:\n",
    "        anime_list[\"Genre \" +genre] = anime_list['Genres'].apply(lambda x: 1 if genre in x.split(', ') else 0)\n",
    "    anime_list.drop(columns=['Genres'], inplace=True)\n",
    "\n",
    "    ## Dealing with Episodes and Duration : calculate total length\n",
    "    anime_list['Episodes'] = pd.to_numeric(anime_list['Episodes'], errors='coerce').fillna(0) #0 if UNKNOWN episodes\n",
    "    hours = anime_list['Duration'].str.extract(r'(\\d+) hr', expand=False).astype(float)\n",
    "    minutes = anime_list['Duration'].str.extract(r'(\\d+) min', expand=False).astype(float)\n",
    "    hours.fillna(0, inplace=True)\n",
    "    minutes.fillna(0, inplace=True)\n",
    "    anime_list['Duration'] = hours * 60 + minutes #0 if UNKNOWN duration\n",
    "    anime_list['Total_Duration'] = anime_list['Duration'] * anime_list['Episodes']\n",
    "\n",
    "    ## Dealing with Aired => get starting date\n",
    "    anime_list['Start_Date'] = pd.to_datetime(anime_list['Aired'].str.split(' to ').str[0], errors='coerce')\n",
    "    anime_list.drop(columns=['Aired'], inplace=True)\n",
    "\n",
    "    ## Dealing with Studios => use one-hot encoding\n",
    "    '''\n",
    "    all_studios = set()\n",
    "    for studio in anime_list['Studios']:\n",
    "        all_studios.update(studio.split(', '))\n",
    "    for studio in all_studios:\n",
    "        anime_list[\"Studio \" + studio] = anime_list['Studios'].apply(lambda x: 1 if studio in x.split(', ') else 0)\n",
    "    anime_list.drop(columns=['Studios'], inplace=True)\n",
    "    '''\n",
    "\n",
    "    ## Dealing with Rating => use one-hot encoding\n",
    "    all_ratings = set()\n",
    "    for rating in anime_list['Rating']:\n",
    "        all_ratings.update(rating.split(', '))\n",
    "    for rating in all_ratings:\n",
    "        anime_list[\"Rating \" + rating] = anime_list['Rating'].apply(lambda x: 1 if rating in x.split(', ') else 0)\n",
    "    anime_list.drop(columns=['Rating'], inplace=True)\n",
    "\n",
    "    ## Dealing with Type => use one-hot encoding\n",
    "    all_types = set()\n",
    "    for type in anime_list['Type']:\n",
    "        all_types.update(type.split(', '))\n",
    "    for type in all_types:\n",
    "        anime_list[\"Type \" + type] = anime_list['Type'].apply(lambda x: 1 if type in x.split(', ') else 0)\n",
    "    anime_list.drop(columns=['Type'], inplace=True)\n",
    "\n",
    "    ## Dealing with Source => use one-hot encoding\n",
    "    all_sources = set()\n",
    "    for source in anime_list['Source']:\n",
    "        all_sources.update(source.split(', '))\n",
    "    for source in all_sources:\n",
    "        anime_list[\"Source \" + source] = anime_list['Source'].apply(lambda x: 1 if source in x.split(', ') else 0)\n",
    "    anime_list.drop(columns=['Source'], inplace=True)\n",
    "\n",
    "    ## Dealing with synopsis\n",
    "    anime_list['Synopsis'] = anime_list['Synopsis'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)).lower())\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    anime_list['Synopsis'] = anime_list['Synopsis'].apply(lambda x  : ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    anime_list['Synopsis'] = anime_list['Synopsis'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
    "    #anime_list['Synopsis'] = anime_list['Synopsis'].apply(lambda x: ' '.join([word for word, pos in pos_tag(word_tokenize(x)) if pos.startswith(('JJ', 'NN', 'VB', 'RB'))])) # add a step to filter names\n",
    "\n",
    "    return anime_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(anime_list):\n",
    "    nbl, nbc = anime_list.shape\n",
    "    print(\"\\nNombre de lignes :\", nbl)\n",
    "    print(\"\\nNombre de colonnes :\", nbc)\n",
    "    print(\"\\nInfos\\n\")\n",
    "    print(anime_list.info())\n",
    "    print(\"\\nDescribe\\n\")\n",
    "    print(anime_list.describe())\n",
    "    print(\"\\nHead\\n\")\n",
    "    print(anime_list.head(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fav_anime_list = [21, 16498, 31964, 38000, 136]\n",
    "fav_anime_list = [21]\n",
    "anime_list = pd.read_parquet('anime/anime.parquet')\n",
    "anime_list = preprocess(anime_list)\n",
    "#show(anime_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_dispersion(df, factor=0.01):\n",
    "    ## Update df, which have values between 0 and 1, to adjust dispersion relatively to 0.5 to a fixed factor, while keeping the values between 0 and 1\n",
    "\n",
    "    # Calculate the current mean absolute deviation from 0.5\n",
    "    current_mad = np.abs(df['similarity'] - 0.5).mean()\n",
    "    \n",
    "    # Scale the values to achieve the desired dispersion relative to 0.5\n",
    "    scaled_values = df['similarity'] + (0.5 - df['similarity']) * (factor / current_mad)\n",
    "    \n",
    "    # Ensure values are between 0 and 1\n",
    "    scaled_values = np.clip(scaled_values, 0, 1)\n",
    "    \n",
    "    df['similarity'] = scaled_values\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_anime(similarities_tab):\n",
    "    #sorted_df = similarities_tab.sort_values(by='similarity', ascending=False)\n",
    "    sorted_df = similarities_tab.sort_values(by='total_similarity', ascending=False)\n",
    "    top_anime_ids = sorted_df.head(30)['anime_id'].tolist()\n",
    "    recommended_animes = []\n",
    "    for anime_id in top_anime_ids:\n",
    "        anime_name = anime_list.loc[anime_list['anime_id'] == anime_id, 'Name'].iloc[0]\n",
    "        recommended_animes.append({'anime_id': anime_id, 'Name': anime_name})\n",
    "    return pd.DataFrame(recommended_animes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Synopsis\n",
    "\n",
    "\n",
    "def extract_keywords(anime_ids, anime_list):\n",
    "    # récupérer tous les synopsis des animes favoris\n",
    "    fav_anime_synopsis = anime_list.loc[anime_list['anime_id'].isin(anime_ids), 'Synopsis'].tolist()\n",
    "    # concaténer l'ensemble de ces synopsis\n",
    "    fav_anime_synopsis = ' '.join(fav_anime_synopsis)\n",
    "    # récupérer les mots clés\n",
    "    fav_anime_keywords = fav_anime_synopsis.split()\n",
    "    fav_anime_keywords = [word.translate(str.maketrans('', '', string.punctuation)).lower() for word in fav_anime_keywords]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    fav_anime_keywords = [word for word in fav_anime_keywords if word not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    fav_anime_keywords = [lemmatizer.lemmatize(word) for word in fav_anime_keywords]\n",
    "    return ' '.join(fav_anime_keywords)\n",
    "\n",
    "\n",
    "def recommendation_synopsis_based(fav_anime_list, anime_list):\n",
    "    # Extraction de mots-clés des synopsis des animes favoris\n",
    "    fav_anime_keywords = extract_keywords(fav_anime_list, anime_list)\n",
    "\n",
    "    anime_ids = anime_list.loc[~anime_list['anime_id'].isin(fav_anime_list), 'anime_id'].values\n",
    "\n",
    "    # Calcul de la similarité cosinus entre les mots-clés générés des animes favoris et les synopsis de tous les autres animes\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix_other_anime = tfidf_vectorizer.fit_transform(anime_list.loc[~anime_list['anime_id'].isin(fav_anime_list), 'Synopsis'])\n",
    "    tfidf_matrix_fav_anime = tfidf_vectorizer.transform([fav_anime_keywords]) \n",
    "    cosine_similarities = cosine_similarity(tfidf_matrix_other_anime, tfidf_matrix_fav_anime)\n",
    "\n",
    "    return pd.DataFrame({'anime_id': anime_ids, 'similarity': cosine_similarities.flatten()})\n",
    "\n",
    "\n",
    "synopsis_cosine_similarities_tab = recommendation_synopsis_based(fav_anime_list, anime_list)\n",
    "print(synopsis_cosine_similarities_tab)\n",
    "\n",
    "synopsis_cosine_similarities_tab = adjust_dispersion(synopsis_cosine_similarities_tab)\n",
    "\n",
    "print(synopsis_cosine_similarities_tab)\n",
    "recommended_animes = recommend_anime(synopsis_cosine_similarities_tab)\n",
    "print(recommended_animes[['anime_id', 'Name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Genre\n",
    "##Limit case : check that every anime in fav_anime_list has not Genre_UNKNOWN, if not delete this anime from the list to build fav_genres_prop\n",
    "\n",
    "def recommendation_genre_based(fav_anime_list, anime_list):\n",
    "    anime_ids = anime_list.loc[~anime_list['anime_id'].isin(fav_anime_list), 'anime_id'].values\n",
    "\n",
    "    if not fav_anime_list:\n",
    "        return pd.DataFrame({'anime_id': anime_ids, 'similarity': 0.5})\n",
    "    \n",
    "    similarities = []\n",
    "\n",
    "    fav_genres = anime_list.loc[anime_list['anime_id'].isin(fav_anime_list), anime_list.filter(regex='^Genre').columns].sum()\n",
    "    fav_genres_prop = fav_genres / fav_genres.sum()\n",
    "\n",
    "    other_anime_genres = anime_list.loc[~anime_list['anime_id'].isin(fav_anime_list), anime_list.filter(regex='^Genre').columns]\n",
    "    for _, row in other_anime_genres.iterrows():\n",
    "        genre_similarity = sum(row[genre] * fav_genres_prop[genre] for genre in fav_genres_prop.index)\n",
    "        similarities.append(genre_similarity)\n",
    "       \n",
    "    return pd.DataFrame({'anime_id': anime_ids, 'similarity': similarities})\n",
    "\n",
    "fav_anime_list = [anime_id for anime_id in fav_anime_list if anime_list.loc[anime_list['anime_id'] == anime_id, 'Genre UNKNOWN'].values[0] == 0]\n",
    "\n",
    "genre_cosine_similarities_tab = recommendation_genre_based(fav_anime_list, anime_list)\n",
    "genre_cosine_similarities_tab = adjust_dispersion(genre_cosine_similarities_tab)\n",
    "\n",
    "print(genre_cosine_similarities_tab)\n",
    "\n",
    "recommended_animes = recommend_anime(genre_cosine_similarities_tab)\n",
    "print(recommended_animes[['anime_id', 'Name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rating\n",
    "##Limit case : check that every anime in fav_anime_list has not Rating UNKNOWN, if not delete this anime from the list to build fav_ratings_prop\n",
    "\n",
    "def recommendation_rating_based(fav_anime_list, anime_list):\n",
    "    anime_ids = anime_list.loc[~anime_list['anime_id'].isin(fav_anime_list), 'anime_id'].values\n",
    "\n",
    "    if not fav_anime_list:\n",
    "        return pd.DataFrame({'anime_id': anime_ids, 'similarity': 0.5})\n",
    "    \n",
    "    similarities = []\n",
    "\n",
    "    fav_ratings = anime_list.loc[anime_list['anime_id'].isin(fav_anime_list), anime_list.filter(regex='^Rating').columns].sum()\n",
    "    fav_ratings_prop = fav_ratings / fav_ratings.sum()\n",
    "\n",
    "    print(fav_ratings_prop)\n",
    "\n",
    "    other_anime_ratings = anime_list.loc[~anime_list['anime_id'].isin(fav_anime_list), anime_list.filter(regex='^Rating').columns]\n",
    "    for _, row in other_anime_ratings.iterrows():\n",
    "        rating_similarity = sum(row[rate] * fav_ratings_prop[rate] for rate in fav_ratings_prop.index)\n",
    "        similarities.append(rating_similarity)\n",
    "       \n",
    "    return pd.DataFrame({'anime_id': anime_ids, 'similarity': similarities})\n",
    "\n",
    "fav_anime_list = [anime_id for anime_id in fav_anime_list if anime_list.loc[anime_list['anime_id'] == anime_id, 'Rating UNKNOWN'].values[0] == 0]\n",
    "\n",
    "rating_cosine_similarities_tab = recommendation_rating_based(fav_anime_list, anime_list)\n",
    "rating_cosine_similarities_tab = adjust_dispersion(rating_cosine_similarities_tab)\n",
    "\n",
    "print(rating_cosine_similarities_tab)\n",
    "\n",
    "recommended_animes = recommend_anime(rating_cosine_similarities_tab)\n",
    "print(recommended_animes[['anime_id', 'Name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Type \n",
    "##Limit case : check that every anime in fav_anime_list has not \"Type UNKNOWN\", if not delete this anime from the list to build fav_types_prop\n",
    "\n",
    "def recommendation_type_based(fav_anime_list, anime_list):\n",
    "    anime_ids = anime_list.loc[~anime_list['anime_id'].isin(fav_anime_list), 'anime_id'].values\n",
    "\n",
    "    if not fav_anime_list:\n",
    "        return pd.DataFrame({'anime_id': anime_ids, 'similarity': 0.5})\n",
    "    \n",
    "    similarities = []\n",
    "\n",
    "    fav_types = anime_list.loc[anime_list['anime_id'].isin(fav_anime_list), anime_list.filter(regex='^Type').columns].sum()\n",
    "    fav_types_prop = fav_types / fav_types.sum()\n",
    "\n",
    "    other_anime_types = anime_list.loc[~anime_list['anime_id'].isin(fav_anime_list), anime_list.filter(regex='^Type').columns]\n",
    "    for _, row in other_anime_types.iterrows():\n",
    "        type_similarity = sum(row[type] * fav_types_prop[type] for type in fav_types_prop.index)\n",
    "        similarities.append(type_similarity)\n",
    "       \n",
    "    return pd.DataFrame({'anime_id': anime_ids, 'similarity': similarities})\n",
    "\n",
    "fav_anime_list = [anime_id for anime_id in fav_anime_list if anime_list.loc[anime_list['anime_id'] == anime_id, 'Type UNKNOWN'].values[0] == 0]\n",
    "\n",
    "print(fav_anime_list)\n",
    "\n",
    "type_cosine_similarities_tab = recommendation_type_based(fav_anime_list, anime_list)\n",
    "type_cosine_similarities_tab = adjust_dispersion(type_cosine_similarities_tab)\n",
    "\n",
    "print(type_cosine_similarities_tab)\n",
    "\n",
    "recommended_animes = recommend_anime(type_cosine_similarities_tab)\n",
    "print(recommended_animes[['anime_id', 'Name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Source \n",
    "##Limit case : check that every anime in fav_anime_list has not \"Source Unknown\", if not delete this anime from the list to build fav_sources_prop\n",
    "\n",
    "def recommendation_source_based(fav_anime_list, anime_list):\n",
    "    anime_ids = anime_list.loc[~anime_list['anime_id'].isin(fav_anime_list), 'anime_id'].values\n",
    "\n",
    "    if not fav_anime_list:\n",
    "        return pd.DataFrame({'anime_id': anime_ids, 'similarity': 0.5})\n",
    "    \n",
    "    similarities = []\n",
    "\n",
    "    fav_sources = anime_list.loc[anime_list['anime_id'].isin(fav_anime_list), anime_list.filter(regex='^Source').columns].sum()\n",
    "    fav_sources_prop = fav_sources / fav_sources.sum()\n",
    "\n",
    "    other_anime_sources = anime_list.loc[~anime_list['anime_id'].isin(fav_anime_list), anime_list.filter(regex='^Source').columns]\n",
    "    for _, row in other_anime_sources.iterrows():\n",
    "        source_similarity = sum(row[source] * fav_sources_prop[source] for source in fav_sources_prop.index)\n",
    "        similarities.append(source_similarity)\n",
    "       \n",
    "    return pd.DataFrame({'anime_id': anime_ids, 'similarity': similarities})\n",
    "\n",
    "fav_anime_list = [anime_id for anime_id in fav_anime_list if anime_list.loc[anime_list['anime_id'] == anime_id, 'Source Unknown'].values[0] == 0]\n",
    "print(fav_anime_list)\n",
    "\n",
    "source_cosine_similarities_tab = recommendation_source_based(fav_anime_list, anime_list)\n",
    "source_cosine_similarities_tab = adjust_dispersion(source_cosine_similarities_tab)\n",
    "\n",
    "print(source_cosine_similarities_tab)\n",
    "\n",
    "recommended_animes = recommend_anime(source_cosine_similarities_tab)\n",
    "print(recommended_animes[['anime_id', 'Name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Duration\n",
    "## Limit case : check that every anime in fav_anime_list has not UNKNOWN for episodes or duration, if not delete this anime from the list to build avg_fav_duration\n",
    "\n",
    "def recommendation_duration_based(fav_anime_list, anime_list):\n",
    "\n",
    "    anime_ids = anime_list.loc[~anime_list['anime_id'].isin(fav_anime_list), 'anime_id'].values\n",
    "\n",
    "    if not fav_anime_list:\n",
    "        return pd.DataFrame({'anime_id': anime_ids, 'similarity': 0.5})\n",
    "    \n",
    "    \n",
    "    similarities = []\n",
    "\n",
    "    avg_fav_duration = anime_list.loc[anime_list['anime_id'].isin(fav_anime_list), 'Total_Duration'].mean()\n",
    "\n",
    "    other_anime_durations = anime_list.loc[~anime_list['anime_id'].isin(fav_anime_list), 'Total_Duration']\n",
    "\n",
    "    for duration in other_anime_durations:\n",
    "        if duration != 0:\n",
    "            relative_difference = abs(duration - avg_fav_duration) / max(duration, avg_fav_duration)\n",
    "            duration_similarity = 1 - relative_difference\n",
    "        else:\n",
    "            duration_similarity = 0 #similarity equals 0 if duration equals 0 (meaning UNKNOW number of episodes or UNKNOW duration)\n",
    "        similarities.append(duration_similarity)\n",
    "\n",
    "    return pd.DataFrame({'anime_id': anime_ids, 'similarity': similarities})\n",
    "\n",
    "#Filtering anime with missing information\n",
    "fav_anime_list = [anime_id for anime_id in fav_anime_list if anime_list.loc[anime_list['anime_id'] == anime_id, 'Episodes'].values[0] != 0]\n",
    "fav_anime_list = [anime_id for anime_id in fav_anime_list if anime_list.loc[anime_list['anime_id'] == anime_id, 'Duration'].values[0] != 0]\n",
    "\n",
    "duration_cosine_similarities_tab = recommendation_duration_based(fav_anime_list, anime_list)\n",
    "duration_cosine_similarities_tab = adjust_dispersion(duration_cosine_similarities_tab)\n",
    "print(duration_cosine_similarities_tab)\n",
    "\n",
    "recommended_animes = recommend_anime(duration_cosine_similarities_tab)\n",
    "print(recommended_animes[['anime_id', 'Name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_fav_anime_list(fav_anime_list, anime_list, feature):\n",
    "    if feature == 'genre':\n",
    "        filtered_fav_anime_list = [anime_id for anime_id in fav_anime_list if anime_list.loc[anime_list['anime_id'] == anime_id, 'Genre UNKNOWN'].values[0] == 0]\n",
    "    elif feature == 'duration':\n",
    "        filtered_fav_anime_list = [anime_id for anime_id in fav_anime_list if anime_list.loc[anime_list['anime_id'] == anime_id, 'Episodes'].values[0] != 0]\n",
    "        filtered_fav_anime_list = [anime_id for anime_id in filtered_fav_anime_list if anime_list.loc[anime_list['anime_id'] == anime_id, 'Duration'].values[0] != 0]\n",
    "    elif feature == 'type':\n",
    "        filtered_fav_anime_list = [anime_id for anime_id in fav_anime_list if anime_list.loc[anime_list['anime_id'] == anime_id, 'Type UNKNOWN'].values[0] == 0]\n",
    "    elif feature == 'source':\n",
    "        filtered_fav_anime_list = [anime_id for anime_id in fav_anime_list if anime_list.loc[anime_list['anime_id'] == anime_id, 'Source Unknown'].values[0] == 0]\n",
    "    elif feature == 'rating':\n",
    "        filtered_fav_anime_list = [anime_id for anime_id in fav_anime_list if anime_list.loc[anime_list['anime_id'] == anime_id, 'Rating UNKNOWN'].values[0] == 0]\n",
    "    else:\n",
    "        filtered_fav_anime_list = fav_anime_list\n",
    "    return filtered_fav_anime_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Final combination \n",
    "\n",
    "genre_cosine_similarities_tab = recommendation_genre_based(preprocess_fav_anime_list(fav_anime_list, anime_list, 'genre'), anime_list)\n",
    "genre_cosine_similarities_tab = adjust_dispersion(genre_cosine_similarities_tab)\n",
    "\n",
    "duration_cosine_similarities_tab = recommendation_duration_based(preprocess_fav_anime_list(fav_anime_list, anime_list, 'duration'), anime_list)\n",
    "duration_cosine_similarities_tab = adjust_dispersion(duration_cosine_similarities_tab)\n",
    "\n",
    "synopsis_cosine_similarities_tab = recommendation_synopsis_based(preprocess_fav_anime_list(fav_anime_list, anime_list, 'synopsis'), anime_list)\n",
    "synopsis_cosine_similarities_tab = adjust_dispersion(synopsis_cosine_similarities_tab)\n",
    "\n",
    "rating_cosine_similarities_tab = recommendation_source_based(preprocess_fav_anime_list(fav_anime_list, anime_list, 'rating'), anime_list)\n",
    "rating_cosine_similarities_tab = adjust_dispersion(rating_cosine_similarities_tab)\n",
    "\n",
    "type_cosine_similarities_tab = recommendation_type_based(preprocess_fav_anime_list(fav_anime_list, anime_list, 'type'), anime_list)\n",
    "type_cosine_similarities_tab = adjust_dispersion(type_cosine_similarities_tab)\n",
    "\n",
    "source_cosine_similarities_tab = recommendation_source_based(preprocess_fav_anime_list(fav_anime_list, anime_list, 'source'), anime_list)\n",
    "source_cosine_similarities_tab = adjust_dispersion(source_cosine_similarities_tab)\n",
    "\n",
    "'''\n",
    "print(genre_cosine_similarities_tab)\n",
    "print(duration_cosine_similarities_tab)\n",
    "print(synopsis_cosine_similarities_tab)\n",
    "print(type_cosine_similarities_tab)\n",
    "print(source_cosine_similarities_tab)\n",
    "print(rating_cosine_similarities_tab)\n",
    "'''\n",
    "\n",
    "\n",
    "combined_tab = pd.merge(genre_cosine_similarities_tab, duration_cosine_similarities_tab, on='anime_id', suffixes=('_genre', '_duration'))\n",
    "combined_tab = pd.merge(combined_tab, synopsis_cosine_similarities_tab, on='anime_id', suffixes=('_', '_synopsis'))\n",
    "combined_tab = pd.merge(combined_tab, type_cosine_similarities_tab, on='anime_id', suffixes=('', '_type'))\n",
    "combined_tab = pd.merge(combined_tab, source_cosine_similarities_tab, on='anime_id', suffixes=('', '_source'))\n",
    "combined_tab = pd.merge(combined_tab, rating_cosine_similarities_tab, on='anime_id', suffixes=('', '_rating'))\n",
    "\n",
    "#print(combined_tab)\n",
    "\n",
    "\n",
    "# Calculate total similarity\n",
    "combined_tab['total_similarity'] = (\n",
    "    0.1 * combined_tab['similarity_genre'] +\n",
    "    0.1 * combined_tab['similarity_duration'] +\n",
    "    0.5 * combined_tab['similarity'] + #synopsis\n",
    "    0.1 * combined_tab['similarity_type'] +\n",
    "    0.1 * combined_tab['similarity_source'] + \n",
    "    0.1 * combined_tab['similarity_rating']\n",
    ")\n",
    "\n",
    "recommended_animes = recommend_anime(combined_tab)\n",
    "print(recommended_animes[['anime_id', 'Name']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
